# Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder

# Load dataset
# Replace 'used_car_data.csv' with your actual dataset file
df = pd.read_csv('used_car_data.csv')

# Feature Engineering
df['Car_Age'] = 2024 - df['Year']  # Calculate car age
df.drop(['Year'], axis=1, inplace=True)  # Drop original 'Year' column

# Handle categorical features
categorical_cols = ['Fuel_Type', 'Transmission', 'Owner']  # Specify categorical columns
encoder = OneHotEncoder(drop='first', sparse=False)
encoded_cols = encoder.fit_transform(df[categorical_cols])
encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))
df = pd.concat([df.drop(categorical_cols, axis=1), encoded_df], axis=1)

# Prepare data for training
X = df.drop(['Selling_Price'], axis=1)  # Features
y = df['Selling_Price']  # Target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Display evaluation metrics
print(f"Mean Squared Error (MSE): {mse}")
print(f"RÂ² Score: {r2}")

# Predict for new data (example)
new_data = np.array([[5, 30000, 1, 0, 0, 1, 0]])  # Replace with actual values
predicted_price = model.predict(new_data)
print(f"Predicted Price for new data: {predicted_price[0]}")
